#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æœ¬åœ°è®­ç»ƒè„šæœ¬ - ç®€åŒ–ç‰ˆ
ä¸“é—¨ä¸ºæœ¬åœ°ä½¿ç”¨ä¼˜åŒ–ï¼Œå»é™¤å¤æ‚çš„æ¯”èµ›å¹³å°åŠŸèƒ½
"""

import os
import sys
import logging
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from models.advanced_controller import AdvancedTLSController, MultiAgentCoordinator
from stable_baselines3 import PPO
from stable_baselines3.common.monitor import Monitor
from stable_baselines3.common.callbacks import BaseCallback
import gymnasium as gym
from gymnasium import spaces
import traci
import sumolib

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def evaluate_training_results(log_dir: str, timesteps: int):
    """è¯„ä¼°è®­ç»ƒç»“æœå¹¶æ˜¾ç¤ºæ•ˆæœ"""
    print("\n" + "="*60)
    print("ğŸ“Š è®­ç»ƒæ•ˆæœè¯„ä¼°æŠ¥å‘Š")
    print("="*60)

    try:
        # è¯»å–TensorBoardæ—¥å¿—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        import glob
        import pandas as pd

        # æŸ¥æ‰¾äº‹ä»¶æ–‡ä»¶
        event_files = glob.glob(os.path.join(log_dir, "events.out.tfevents.*"))

        if event_files:
            print("ğŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
            print(f"  â€¢ è®­ç»ƒæ­¥æ•°: {timesteps:,}")
            print(f"  â€¢ è®­ç»ƒæ—¶é•¿: å·²å®Œæˆ")
            print(f"  â€¢ æ¨¡å‹ä¿å­˜: âœ… æˆåŠŸ")
        else:
            print("ğŸ“ˆ è®­ç»ƒç»Ÿè®¡:")
            print(f"  â€¢ è®­ç»ƒæ­¥æ•°: {timesteps:,}")
            print(f"  â€¢ è®­ç»ƒæ—¶é•¿: å·²å®Œæˆ")
            print(f"  â€¢ æ¨¡å‹ä¿å­˜: âœ… æˆåŠŸ")

    except Exception as e:
        logger.warning(f"è¯»å–è®­ç»ƒç»Ÿè®¡å¤±è´¥: {e}")

    # ç»™å‡ºæ•ˆæœåˆ¤æ–­å»ºè®®
    print("\nğŸ¯ æ•ˆæœè¯„ä¼°å»ºè®®:")

    if timesteps >= 500000:
        print("  âœ… è®­ç»ƒæ­¥æ•°å……è¶³ - é¢„æœŸæ•ˆæœè‰¯å¥½")
        print("  ğŸ† é€‚åˆæ¯”èµ›ä½¿ç”¨")
    elif timesteps >= 200000:
        print("  âœ… è®­ç»ƒæ­¥æ•°é€‚ä¸­ - é¢„æœŸæ•ˆæœä¸é”™")
        print("  ğŸ‘ é€‚åˆæ—¥å¸¸ä½¿ç”¨")
    elif timesteps >= 50000:
        print("  âš ï¸  è®­ç»ƒæ­¥æ•°è¾ƒå°‘ - æ•ˆæœå¯èƒ½ä¸€èˆ¬")
        print("  ğŸ’¡ å»ºè®®å¢åŠ è®­ç»ƒæ­¥æ•°")
    else:
        print("  âŒ è®­ç»ƒæ­¥æ•°å¤ªå°‘ - æ•ˆæœå¯èƒ½è¾ƒå·®")
        print("  ğŸ”„ å»ºè®®é‡æ–°è®­ç»ƒæ›´å¤šæ­¥æ•°")

    print("\nğŸ“‹ ä¸‹ä¸€æ­¥å»ºè®®:")
    print("  1. ğŸ§ª æµ‹è¯•æ¨¡å‹: python start_local.py (é€‰æ‹©4)")
    print("  2. ğŸ“Š æŸ¥çœ‹æ›²çº¿: tensorboard --logdir " + log_dir)
    print("  3. ğŸ”„ å¦‚æœæ•ˆæœä¸å¥½ï¼Œå¯ä»¥é‡æ–°è®­ç»ƒ")

    # æ•ˆæœåˆ¤æ–­æ ‡å‡†
    print("\nğŸ“ æ•ˆæœåˆ¤æ–­æ ‡å‡†:")
    print("  âœ… å¥½æ¨¡å‹ç‰¹å¾:")
    print("     â€¢ æµ‹è¯•æ—¶è½¦è¾†æµç•…é€šè¡Œ")
    print("     â€¢ ç­‰å¾…æ—¶é—´æ˜æ˜¾å‡å°‘")
    print("     â€¢ å¾ˆå°‘å‡ºç°é•¿æ—¶é—´æ‹¥å µ")
    print("  âŒ éœ€è¦é‡æ–°è®­ç»ƒ:")
    print("     â€¢ æµ‹è¯•æ—¶ç»å¸¸æ‹¥å µ")
    print("     â€¢ ç­‰å¾…æ—¶é—´å¾ˆé•¿")
    print("     â€¢ ä¿¡å·ç¯åˆ‡æ¢ä¸åˆç†")

    print("="*60)


class SimpleTrafficEnv(gym.Env):
    """ç®€åŒ–çš„æœ¬åœ°äº¤é€šç¯å¢ƒ"""
    
    def __init__(self, sumocfg_file: str, tls_ids: list, scenario_path: str, gui_enabled: bool = False):
        super().__init__()
        
        self.sumocfg_file = sumocfg_file
        self.tls_ids = tls_ids
        self.scenario_path = scenario_path
        self.gui_enabled = gui_enabled
        self.max_steps = 3600
        self.step_count = 0
        
        # è§‚æµ‹å’ŒåŠ¨ä½œç©ºé—´
        self.single_obs_dim = 20  # ç®€åŒ–è§‚æµ‹ç©ºé—´
        self.num_agents = len(tls_ids)
        
        self.observation_space = spaces.Box(
            low=-np.inf, high=np.inf,
            shape=(self.num_agents * self.single_obs_dim,),
            dtype=np.float32
        )
        self.action_space = spaces.MultiDiscrete([2] * self.num_agents)  # ç®€åŒ–åŠ¨ä½œç©ºé—´
        
        # æ§åˆ¶å™¨
        self.controllers = []
        self.coordinator = None
        self._sumo_started = False
        
        # æ€§èƒ½ç»Ÿè®¡
        self.episode_rewards = []
        
        # å¯åŠ¨SUMO
        self._start_sumo()
        
    def _start_sumo(self):
        """å¯åŠ¨SUMO"""
        try:
            if self.gui_enabled:
                sumoBinary = sumolib.checkBinary('sumo-gui')
                sumo_cmd = [sumoBinary, "-c", self.sumocfg_file, "--start", "--quit-on-end"]
            else:
                sumoBinary = sumolib.checkBinary('sumo')
                sumo_cmd = [sumoBinary, "-c", self.sumocfg_file, "--quit-on-end", "--no-step-log"]
            
            traci.start(sumo_cmd)
            self._sumo_started = True
            logger.info("SUMOå¯åŠ¨æˆåŠŸ")
            
        except Exception as e:
            logger.error(f"å¯åŠ¨SUMOå¤±è´¥: {e}")
            raise
            
    def reset(self, seed: Optional[int] = None, options: Optional[Dict] = None):
        """é‡ç½®ç¯å¢ƒ"""
        super().reset(seed=seed)
        
        try:
            # é‡æ–°åŠ è½½ä»¿çœŸ
            sumo_cmd = ["-c", self.sumocfg_file, "--quit-on-end"]
            if self.gui_enabled:
                sumo_cmd.append("--start")
            else:
                sumo_cmd.append("--no-step-log")
            traci.load(sumo_cmd)
            
            self.step_count = 0
            
            # åˆ›å»ºæ§åˆ¶å™¨
            additional_file = os.path.join(self.scenario_path, 'additional.xml')
            config = {'coordination_enabled': True}  # ç®€åŒ–é…ç½®
            
            self.controllers = [
                AdvancedTLSController(tls_id, additional_file, config) 
                for tls_id in self.tls_ids
            ]
            
            # åˆ›å»ºåè°ƒå™¨
            self.coordinator = MultiAgentCoordinator(self.controllers, config)
            
            # è·å–åˆå§‹è§‚æµ‹
            observations = []
            for controller in self.controllers:
                obs = controller.reset()
                # åªå–å‰20ç»´ï¼Œç®€åŒ–è§‚æµ‹
                observations.append(obs[:20])
                
            observation = np.concatenate(observations).astype(np.float32)
            info = {"step": self.step_count}
            
            return observation, info
            
        except Exception as e:
            logger.error(f"é‡ç½®å¤±è´¥: {e}")
            observation = np.zeros(self.observation_space.shape, dtype=np.float32)
            return observation, {"error": str(e)}
            
    def step(self, action):
        """æ‰§è¡Œä¸€æ­¥"""
        try:
            # æ‰§è¡Œä»¿çœŸæ­¥
            traci.simulationStep()
            self.step_count += 1
            
            # æ‰§è¡ŒåŠ¨ä½œå¹¶æ”¶é›†å¥–åŠ±
            rewards = []
            observations = []
            
            for i, (controller, agent_action) in enumerate(zip(self.controllers, action)):
                reward = controller.update(self.step_count, agent_action)
                obs = controller.get_enhanced_observation()
                
                rewards.append(reward)
                observations.append(obs[:20])  # åªå–å‰20ç»´
                
            # è®¡ç®—å¹³å‡å¥–åŠ±
            total_reward = np.mean(rewards)
            
            # æ‹¼æ¥è§‚æµ‹
            observation = np.concatenate(observations).astype(np.float32)
            
            # æ£€æŸ¥ç»ˆæ­¢æ¡ä»¶
            terminated = self.step_count >= self.max_steps
            truncated = False
            
            info = {
                "step": self.step_count,
                "individual_rewards": rewards,
                "avg_waiting_time": np.mean([c.get_performance_metrics().get('avg_waiting_time', 0) for c in self.controllers])
            }
            
            return observation, total_reward, terminated, truncated, info
            
        except Exception as e:
            logger.error(f"æ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")
            observation = np.zeros(self.observation_space.shape, dtype=np.float32)
            return observation, -100.0, True, False, {"error": str(e)}
            
    def close(self):
        """å…³é—­ç¯å¢ƒ"""
        try:
            if self._sumo_started:
                traci.close()
                self._sumo_started = False
                logger.info("ç¯å¢ƒå·²å…³é—­")
        except Exception as e:
            logger.error(f"å…³é—­ç¯å¢ƒå¤±è´¥: {e}")


class SimpleCallback(BaseCallback):
    """ç®€å•çš„è®­ç»ƒå›è°ƒ"""
    
    def __init__(self, save_freq: int = 10000, verbose: int = 1):
        super().__init__(verbose)
        self.save_freq = save_freq
        self.best_mean_reward = -np.inf
        
    def _on_step(self) -> bool:
        # å®šæœŸä¿å­˜æ¨¡å‹
        if self.num_timesteps % self.save_freq == 0:
            model_path = f"model_checkpoint_{self.num_timesteps}.zip"
            self.model.save(model_path)
            logger.info(f"æ¨¡å‹å·²ä¿å­˜: {model_path}")
            
        return True


def create_local_env(scenario_name: str = "2x2_grid", gui_enabled: bool = False):
    """åˆ›å»ºæœ¬åœ°ç¯å¢ƒ"""
    scenario_path = f"scenarios/{scenario_name}"
    sumocfg_file = os.path.join(scenario_path, "config.sumocfg")
    
    if not os.path.exists(sumocfg_file):
        raise FileNotFoundError(f"åœºæ™¯é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {sumocfg_file}")
        
    # è·å–äº¤é€šä¿¡å·ç¯ID
    try:
        sumo_cmd = [sumolib.checkBinary('sumo'), "-c", sumocfg_file]
        traci.start(sumo_cmd, label="temp_check")
        tls_ids = traci.trafficlight.getIDList()
        traci.close()
    except Exception as e:
        logger.warning(f"è·å–äº¤é€šä¿¡å·ç¯IDå¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ID")
        tls_ids = ["A0", "A1", "B0", "B1"]
        
    return SimpleTrafficEnv(sumocfg_file, tls_ids, scenario_path, gui_enabled)


def train_local_model(scenario: str = "competition",
                     timesteps: int = 200000,
                     gui: bool = False,
                     learning_rate: float = 3e-4):
    """æœ¬åœ°è®­ç»ƒæ¨¡å‹"""
    try:
        logger.info("å¼€å§‹æœ¬åœ°è®­ç»ƒ")
        
        # åˆ›å»ºç¯å¢ƒ
        env = create_local_env(scenario, gui)
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_dir = f"local_logs/{timestamp}"
        os.makedirs(log_dir, exist_ok=True)
        
        # åŒ…è£…Monitor
        env = Monitor(env, filename=os.path.join(log_dir, "monitor.csv"))
        
        # åˆ›å»ºPPOæ¨¡å‹
        model = PPO(
            policy="MlpPolicy",
            env=env,
            learning_rate=learning_rate,
            n_steps=2048,
            batch_size=64,
            verbose=1,
            tensorboard_log=log_dir
        )
        
        # åˆ›å»ºå›è°ƒ
        callback = SimpleCallback(save_freq=10000)
        
        # å¼€å§‹è®­ç»ƒ
        logger.info(f"å¼€å§‹è®­ç»ƒï¼Œæ€»æ­¥æ•°: {timesteps}")
        model.learn(total_timesteps=timesteps, callback=callback, progress_bar=True)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = os.path.join(log_dir, "final_model.zip")
        model.save(final_model_path)
        logger.info(f"è®­ç»ƒå®Œæˆï¼Œæ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")

        # è‡ªåŠ¨è¯„ä¼°è®­ç»ƒæ•ˆæœ
        evaluate_training_results(log_dir, timesteps)

        env.close()
        return final_model_path
        
    except Exception as e:
        logger.error(f"è®­ç»ƒå¤±è´¥: {e}")
        return None


def test_local_model(model_path: str, scenario: str = "2x2_grid", episodes: int = 3):
    """æµ‹è¯•æœ¬åœ°æ¨¡å‹"""
    try:
        logger.info(f"å¼€å§‹æµ‹è¯•æ¨¡å‹: {model_path}")
        
        # åˆ›å»ºç¯å¢ƒï¼ˆå¯ç”¨GUIï¼‰
        env = create_local_env(scenario, gui_enabled=True)
        
        # åŠ è½½æ¨¡å‹
        model = PPO.load(model_path, env=env)
        
        # è¿è¡Œæµ‹è¯•
        for episode in range(episodes):
            obs, info = env.reset()
            episode_reward = 0
            step_count = 0
            
            logger.info(f"å¼€å§‹ç¬¬ {episode + 1} å›åˆæµ‹è¯•")
            
            while step_count < 3600:
                action, _states = model.predict(obs, deterministic=True)
                obs, reward, terminated, truncated, info = env.step(action)
                
                episode_reward += reward
                step_count += 1
                
                if terminated or truncated:
                    break
                    
            logger.info(f"ç¬¬ {episode + 1} å›åˆç»“æŸï¼Œå¥–åŠ±: {episode_reward:.2f}ï¼Œæ­¥æ•°: {step_count}")
            
        env.close()
        logger.info("æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æœ¬åœ°äº¤é€šä¿¡å·ç¯æ§åˆ¶è®­ç»ƒ")
    parser.add_argument("--mode", choices=["train", "test"], default="train", help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--scenario", default="competition", help="åœºæ™¯åç§°")
    parser.add_argument("--timesteps", type=int, default=200000, help="è®­ç»ƒæ­¥æ•°")
    parser.add_argument("--gui", action="store_true", help="å¯ç”¨GUI")
    parser.add_argument("--model-path", help="æ¨¡å‹è·¯å¾„ï¼ˆæµ‹è¯•æ¨¡å¼éœ€è¦ï¼‰")
    parser.add_argument("--learning-rate", type=float, default=3e-4, help="å­¦ä¹ ç‡")
    parser.add_argument("--episodes", type=int, default=3, help="æµ‹è¯•å›åˆæ•°")
    
    args = parser.parse_args()
    
    if args.mode == "train":
        model_path = train_local_model(
            scenario=args.scenario,
            timesteps=args.timesteps,
            gui=args.gui,
            learning_rate=args.learning_rate
        )
        if model_path:
            print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
            print(f"ğŸ’¡ å¿«é€Ÿæµ‹è¯•: python start_local.py (é€‰æ‹©èœå•4)")
            print(f"ğŸ“Š è¯¦ç»†åˆ†æ: tensorboard --logdir {os.path.dirname(model_path)}")
        return 0 if model_path else 1
        
    elif args.mode == "test":
        if not args.model_path:
            logger.error("æµ‹è¯•æ¨¡å¼éœ€è¦æŒ‡å®šæ¨¡å‹è·¯å¾„")
            return 1
        success = test_local_model(args.model_path, args.scenario, args.episodes)
        return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
